{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset FinanceBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load OpenAI access\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "from azure_openai_conn import OpenAIembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn huggingface dataset to pd\n",
    "# images = fashion[\"image\"]\n",
    "# data = fashion.remove_columns(\"image\")\n",
    "# product_df = data.to_pandas()\n",
    "# product_data = product_df.reset_index(drop=True).to_dict(orient=\"index\")\n",
    "\n",
    "if os.path.isfile('../../data/financebench_sample_150.csv'):\n",
    "    df = pd.read_csv('../../data/financebench_sample_150.csv')\n",
    "else:    \n",
    "    ds = load_dataset(\"PatronusAI/financebench\")\n",
    "    df = pd.DataFrame(ds)\n",
    "    all_dicts = []\n",
    "    for index, row in df.iterrows():    \n",
    "        dictionary = row['train']    \n",
    "        all_dicts.append(dictionary)\n",
    "    df = pd.DataFrame(all_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destination_folder = '../../data/financebench'\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['doc_link']\n",
    "        doc_name = row['doc_name']\n",
    "        doc_name_with_extension = doc_name + '.pdf'        \n",
    "        file_path = os.path.join(destination_folder, doc_name_with_extension)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:            \n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded: {doc_name_with_extension}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {doc_name_with_extension} ({url})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_persist_pdf(destination_folder) -> Qdrant:\n",
    "    pdf_folder_path = destination_folder\n",
    "    documents = []\n",
    "    for file in os.listdir(pdf_folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path, file)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    # todo: smarter spliter\n",
    "    # https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/scripts/prepdocslib/textsplitter.py\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500, chunk_overlap=100, add_start_index=True # https://github.com/langchain-ai/langchain/blob/master/templates/rag-redis/ingest.py\n",
    "    )\n",
    "    \n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIembeddings()\n",
    "\n",
    "    qdrant = Qdrant.from_documents(\n",
    "        chunked_documents,\n",
    "        embeddings,\n",
    "        path=destination_folder,\n",
    "        collection_name=\"financebench\")   \n",
    "\n",
    "    return qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = load_chunk_persist_pdf(destination_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".genai0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
