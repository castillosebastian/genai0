{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://github.com/castillosebastian/genai0/blob/main/exp/RAG_toy.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Over 'FinanceBench' tiny database**:\n",
    "\n",
    "-[MICROSOFT_2023_10K](../data/financebench/MICROSOFT_2023_10K.pdf)    \n",
    "-[JOHNSON&JOHNSON_2022Q4_EARNINGS](../data/financebench/JOHNSON&JOHNSON_2022Q4_EARNINGS.pdf)   \n",
    "-[Pfizer_2023Q2_10Q](../data/financebench/Pfizer_2023Q2_10Q.pdf)   \n",
    "-[BESTBUY_2017_10K](../data/financebench/BESTBUY_2017_10K.pdf)   \n",
    "-[BESTBUY_2019_10K](../data/financebench/BESTBUY_2019_10K.pdf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete with Keys!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_TYPE='azure'\n",
    "OPENAI_API_VERSION='2023-05-15'\n",
    "AZURE_OPENAI_ENDPOINT='https://usesharedaopenai001.openai.azure.com/'\n",
    "OPENAI_API_KEY='b82effcf491e45a088b1cd578713311c'\n",
    "OPENAI_EMBEDDINGS_MODEL_NAME='text-embedding-ada-002'\n",
    "SEARCH_SERVICE_ENDPOINT='https://genai0.search.windows.net'\n",
    "SEARCH_SERVICE_API_KEY='lvhCA67EeE3JRyxyem5L0wGJSfOxscm2jft887ECdJAzSeDzoCNZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here cames the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json  \n",
    "import wget\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from azure.core.credentials import AzureKeyCredential \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Variables-------------------------------------------------------\n",
    "index   = \"azure-cognitive-search-vector-demo\"\n",
    "os.environ[\"OPENAI_API_TYPE\"]       = OPENAI_API_TYPE\n",
    "azure_search_endpoint               = SEARCH_SERVICE_ENDPOINT\n",
    "MODEL                               = \"gtp35turbo-latest\"\n",
    "service_endpoint                    = SEARCH_SERVICE_ENDPOINT\n",
    "index_name                          = index\n",
    "key                                 = SEARCH_SERVICE_API_KEY\n",
    "model                               = \"text-embedding-ada-002\" \n",
    "credential                          = AzureKeyCredential(key)\n",
    "COMPLETION_TOKENS                = 1000\n",
    "top_search_vector_k              = 5\n",
    "\n",
    "# Some helper functions---------------------------------------------\n",
    "def OpenAIembeddings():\n",
    "    open_ai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-ada-002\",\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        chunk_size=1000,\n",
    "    )\n",
    "    return open_ai_embeddings\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = OPENAI_API_KEY,  \n",
    "  api_version = OPENAI_API_VERSION,\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "def generate_embeddings(text, model=model):\n",
    "        return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Retriever------------------------------------------------------------\n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask your question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question:\n",
    "# the question to ask - enable just one\n",
    "QUESTION = \"What is the revenue of Pfizer\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query = VectorizedQuery(vector=generate_embeddings(QUESTION), k_nearest_neighbors=5, fields=\"contentVector\") \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    include_total_count=True,\n",
    "    select=[\"id\", \"company_name\", \"source\", \"doc_type\", \"page_content\"],\n",
    ")  \n",
    "#results.get_count()\n",
    "# Format Azure AI Search results as an ordered dictionary\n",
    "from collections import OrderedDict\n",
    "ordered_results = OrderedDict()\n",
    "for result in results:    \n",
    "    ordered_results[result['id']]={\n",
    "        \"score\": result['@search.score'],\n",
    "        \"company_name\": result['company_name'],\n",
    "        \"source\": result['source'],\n",
    "        \"doc_type\": result['doc_type'],\n",
    "        \"page_content\": result['page_content']\n",
    "    }\n",
    "# From the ordered dictionary, build the \"Documents\" array, needed by langchain \"qa_with_sources\" chain\n",
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    references = f'Company: {value[\"company_name\"]}, SEC report: {value[\"doc_type\"]} \\n (reference doc:\"{value[\"source\"]}\", reference_score:{value[\"score\"]} - id:{key}).' \n",
    "    top_docs.append(Document(page_content=value[\"page_content\"], metadata={\"source\": references}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/><br/><b>RAG_toybot final answer:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The revenue of Pfizer for the three months ended July 2, 2023, was $12,734 million, and for the six months ended July 2, 2023, it was $31,015 million. These figures are for the Global Biopharmaceuticals Business (Biopharma) segment. Specific revenue breakdowns for major products include $1,488 million for Comirnaty direct sales and alliance revenues, $143 million for Paxlovid, $1,762 million for Eliquis alliance revenues and direct sales, and $1,388 million for the Prevnar family. However, it should be noted that these figures are subject to change and are based on forecasts and estimates. The full revenue details can be found in Pfizer's SEC report: 10Q.\n",
       "SOURCES: Company: PFIZER, SEC report: 10Q (reference doc:\"../../data/financebench/Pfizer_2023Q2_10Q.pdf\", reference_score:0.88448966 - id:703)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the Open AI deployment\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(model_name=MODEL)\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "\n",
    "chain = load_qa_with_sources_chain(llm, chain_type='stuff')\n",
    "  \n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})\n",
    "\n",
    "# Print the final result, including the citation(s)\n",
    "from IPython.display import display, HTML, Markdown\n",
    "display(HTML(f\"<br/><br/><b>RAG_toybot final answer:</b>\"))\n",
    "display(Markdown(response['output_text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".genai0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
