{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324e70d1-9876-44ea-88e0-499d2defa890",
   "metadata": {},
   "source": [
    "# Sec Financial Statement Data Sets Tools - Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5fd5e7-16f8-406b-b5e4-2b23cf403638",
   "metadata": {},
   "source": [
    "## TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901fe0d2-d257-4b2d-847e-596438672c24",
   "metadata": {},
   "source": [
    "This notebook gives a first introduction into using the secfsdstools (Sec Financial Data Sets Tools) python package: https://pypi.org/project/secfsdstools/\n",
    "\n",
    "It is designed to work with the data provided by the \"Sec Financial Statement Data Sets\" (SFSDS)(https://www.sec.gov/dera/data/financial-statement-data-sets).\n",
    "\n",
    "The SFSDS contains data from all reports that were filed with the sec since 2012. For instance all anual and quarter reports. The main assets that can be retrieved from this data set are the financial statemens (balance sheet, income statement, and cash flow).\n",
    "\n",
    "First, this notebook shows how the library is installed and configured. After that, it shows how the financial statements can be extracted from the data set.\n",
    "\n",
    "For a detailed definition of the data set see https://www.sec.gov/files/aqfs.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ca081-3a9f-42b9-bc85-496c42821e7e",
   "metadata": {},
   "source": [
    "## Principles / Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4edea-7b2a-4efd-9b63-96257251a803",
   "metadata": {},
   "source": [
    "The goal is bulk processing of the data.\n",
    "\n",
    "To improve efficiency, the zip files are downloaded and indexed using a SQLite database table.\n",
    "The index table contains information on all filed reports, over 500,000 in total. The first\n",
    "download will take a couple of minutes but after that, all the data is on your local harddisk.\n",
    "\n",
    "Using the index in the sqlite db allows for direct extraction of data for a specific report from the\n",
    "appropriate zip file, reducing the need to open and search through each zip file.\n",
    "\n",
    "Moreover, the downloaded zip files are converted to the parquet format which provides faster read access\n",
    "to the data compared to reading the csv files inside the zip files.\n",
    "\n",
    "The library is designed to have a low memory footprint, only parsing and reading the data for a specific\n",
    "report into pandas dataframe tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66226a-90c8-402e-9c61-85bb656e2e21",
   "metadata": {},
   "source": [
    "## Installation\n",
    "In order to install the library, just use pip install:\n",
    "```\n",
    "pip install secfsdstools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67276-7d80-4138-be4b-53c32126f9a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure logging in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f97ba9-010c-45e3-ab0b-2e87c0099230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to ensure that the logging statements are shown in juypter output, run this cell\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe6107-00af-4603-9c31-2282d92e3a37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure table output for Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3daf46-7c76-40f8-8790-296b7495c4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ensure that all columns are shown and that colum content is not cut\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85678c-22c7-422d-8d86-00adc9008124",
   "metadata": {},
   "source": [
    "## Configuration / Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076cff1-a3a6-486b-a681-ee27db71778f",
   "metadata": {},
   "source": [
    "In order to be used, the library needs to know where to store the compressed files from the Financial Statement Data Sets and where to store the sqlite database file. This is configured in a configuration file.\n",
    "\n",
    "If you don't provide a config file, one will be created the first time you use the api. The configuration file will be created inside your home\n",
    "directory. You can then change the content of it or directly start with the downloading of the data.\n",
    "\n",
    "```\n",
    "[DEFAULT]\n",
    "downloaddirectory = <userhome>/secfsdstools/data/dld\n",
    "parquetdirectory = <userhome>/secfsdools/data/parquet\n",
    "dbdirectory = <userhome>/secfsdstools/data/db\n",
    "useragentemail = your.email@goeshere.com\n",
    "```\n",
    "\n",
    "The downloaddirectory is the folder in which the compressed data files are downloaded.\n",
    "The parquetdirectory is the folder in which the transfomred parquet version is stored.\n",
    "The dbdirectory will contain sqlite db file.\n",
    "The useragentemail is set inside the header when requests to sec.gov are made. This should be your email-address, however, since we are only making very few requests, it doesn't really matter if you change it or not.\n",
    "\n",
    "If you want to start the download of the data \"manually\", just call the update method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8c6cd6-9713-4f85-afbf-fdebb7a02cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 14:40:24,997 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n",
      "2023-12-15 14:40:24,999 [INFO] configmgt  SQLite db directory does not exist, creating it at /home/sebacastillo/genai0/data/db\n",
      "2023-12-15 14:40:25,000 [INFO] configmgt  Download directory does not exist, creating it at /home/sebacastillo/genai0/secfsdstools/data/dld\n",
      "2023-12-15 14:40:25,001 [INFO] configmgt  Parquet directory does not exist, creating it at /home/sebacastillo/genai0/data/parquet\n",
      "2023-12-15 14:40:25,003 [INFO] updateprocess  Check if new report zip files are available...\n",
      "2023-12-15 14:40:25,483 [INFO] updateprocess  check if there are new files to download from sec.gov ...\n",
      "2023-12-15 14:40:27,679 [INFO] parallelexecution      items to process: 59\n",
      "2023-12-15 14:40:27,684 [INFO] basedownloading      start to download 2023q3.zip \n",
      "2023-12-15 14:40:27,699 [INFO] basedownloading      start to download 2023q2.zip \n",
      "2023-12-15 14:40:27,700 [INFO] basedownloading      start to download 2023q1.zip \n",
      "2023-12-15 14:40:54,487 [INFO] parallelexecution      commited chunk: 0\n",
      "2023-12-15 14:40:54,488 [INFO] basedownloading      start to download 2022q4.zip \n",
      "2023-12-15 14:40:54,489 [INFO] basedownloading      start to download 2022q3.zip \n",
      "2023-12-15 14:40:54,490 [INFO] basedownloading      start to download 2022q2.zip \n",
      "2023-12-15 14:41:19,394 [INFO] parallelexecution      commited chunk: 3\n",
      "2023-12-15 14:41:19,397 [INFO] basedownloading      start to download 2022q1.zip \n",
      "2023-12-15 14:41:19,397 [INFO] basedownloading      start to download 2021q4.zip \n",
      "2023-12-15 14:41:19,397 [INFO] basedownloading      start to download 2021q3.zip \n",
      "2023-12-15 14:41:44,633 [INFO] parallelexecution      commited chunk: 6\n",
      "2023-12-15 14:41:44,635 [INFO] basedownloading      start to download 2021q2.zip \n",
      "2023-12-15 14:41:44,635 [INFO] basedownloading      start to download 2021q1.zip \n",
      "2023-12-15 14:41:44,636 [INFO] basedownloading      start to download 2020q4.zip \n",
      "2023-12-15 14:42:08,560 [INFO] parallelexecution      commited chunk: 9\n",
      "2023-12-15 14:42:08,562 [INFO] basedownloading      start to download 2020q3.zip \n",
      "2023-12-15 14:42:08,563 [INFO] basedownloading      start to download 2020q2.zip \n",
      "2023-12-15 14:42:08,568 [INFO] basedownloading      start to download 2020q1.zip \n",
      "2023-12-15 14:42:30,497 [INFO] parallelexecution      commited chunk: 12\n",
      "2023-12-15 14:42:30,498 [INFO] basedownloading      start to download 2019q4.zip \n",
      "2023-12-15 14:42:30,499 [INFO] basedownloading      start to download 2019q3.zip \n",
      "2023-12-15 14:42:30,501 [INFO] basedownloading      start to download 2019q2.zip \n",
      "2023-12-15 14:42:51,548 [INFO] parallelexecution      commited chunk: 15\n",
      "2023-12-15 14:42:51,549 [INFO] basedownloading      start to download 2019q1.zip \n",
      "2023-12-15 14:42:51,549 [INFO] basedownloading      start to download 2018q4.zip \n",
      "2023-12-15 14:42:51,550 [INFO] basedownloading      start to download 2018q3.zip \n",
      "2023-12-15 14:43:12,585 [INFO] parallelexecution      commited chunk: 18\n",
      "2023-12-15 14:43:12,587 [INFO] basedownloading      start to download 2018q2.zip \n",
      "2023-12-15 14:43:12,588 [INFO] basedownloading      start to download 2018q1.zip \n",
      "2023-12-15 14:43:12,592 [INFO] basedownloading      start to download 2017q4.zip \n",
      "2023-12-15 14:43:33,564 [INFO] parallelexecution      commited chunk: 21\n",
      "2023-12-15 14:43:33,565 [INFO] basedownloading      start to download 2017q3.zip \n",
      "2023-12-15 14:43:33,565 [INFO] basedownloading      start to download 2017q2.zip \n",
      "2023-12-15 14:43:33,566 [INFO] basedownloading      start to download 2017q1.zip \n",
      "2023-12-15 14:43:55,010 [INFO] parallelexecution      commited chunk: 24\n",
      "2023-12-15 14:43:55,011 [INFO] basedownloading      start to download 2016q4.zip \n",
      "2023-12-15 14:43:55,013 [INFO] basedownloading      start to download 2016q3.zip \n",
      "2023-12-15 14:43:55,015 [INFO] basedownloading      start to download 2016q2.zip \n",
      "2023-12-15 14:44:15,576 [INFO] parallelexecution      commited chunk: 27\n",
      "2023-12-15 14:44:15,577 [INFO] basedownloading      start to download 2016q1.zip \n",
      "2023-12-15 14:44:15,578 [INFO] basedownloading      start to download 2015q4.zip \n",
      "2023-12-15 14:44:15,579 [INFO] basedownloading      start to download 2015q3.zip \n",
      "2023-12-15 14:44:38,372 [INFO] parallelexecution      commited chunk: 30\n",
      "2023-12-15 14:44:38,374 [INFO] basedownloading      start to download 2015q2.zip \n",
      "2023-12-15 14:44:38,375 [INFO] basedownloading      start to download 2015q1.zip \n",
      "2023-12-15 14:44:38,376 [INFO] basedownloading      start to download 2014q4.zip \n",
      "2023-12-15 14:45:03,493 [INFO] parallelexecution      commited chunk: 33\n",
      "2023-12-15 14:45:03,495 [INFO] basedownloading      start to download 2014q3.zip \n",
      "2023-12-15 14:45:03,495 [INFO] basedownloading      start to download 2014q2.zip \n",
      "2023-12-15 14:45:03,496 [INFO] basedownloading      start to download 2014q1.zip \n",
      "2023-12-15 14:45:28,657 [INFO] parallelexecution      commited chunk: 36\n",
      "2023-12-15 14:45:28,659 [INFO] basedownloading      start to download 2013q4.zip \n",
      "2023-12-15 14:45:28,660 [INFO] basedownloading      start to download 2013q3.zip \n",
      "2023-12-15 14:45:28,660 [INFO] basedownloading      start to download 2013q2.zip \n",
      "2023-12-15 14:45:55,228 [INFO] parallelexecution      commited chunk: 39\n",
      "2023-12-15 14:45:55,229 [INFO] basedownloading      start to download 2013q1.zip \n",
      "2023-12-15 14:45:55,229 [INFO] basedownloading      start to download 2012q4.zip \n",
      "2023-12-15 14:45:55,230 [INFO] basedownloading      start to download 2012q3.zip \n",
      "2023-12-15 14:46:20,769 [INFO] parallelexecution      commited chunk: 42\n",
      "2023-12-15 14:46:20,770 [INFO] basedownloading      start to download 2012q2.zip \n",
      "2023-12-15 14:46:20,771 [INFO] basedownloading      start to download 2012q1.zip \n",
      "2023-12-15 14:46:20,778 [INFO] basedownloading      start to download 2011q4.zip \n",
      "2023-12-15 14:46:41,628 [INFO] parallelexecution      commited chunk: 45\n",
      "2023-12-15 14:46:41,629 [INFO] basedownloading      start to download 2011q3.zip \n",
      "2023-12-15 14:46:41,637 [INFO] basedownloading      start to download 2011q2.zip \n",
      "2023-12-15 14:46:41,640 [INFO] basedownloading      start to download 2011q1.zip \n",
      "2023-12-15 14:46:51,544 [INFO] parallelexecution      commited chunk: 48\n",
      "2023-12-15 14:46:51,553 [INFO] basedownloading      start to download 2010q4.zip \n",
      "2023-12-15 14:46:51,558 [INFO] basedownloading      start to download 2010q3.zip \n",
      "2023-12-15 14:46:51,559 [INFO] basedownloading      start to download 2010q2.zip \n",
      "2023-12-15 14:46:55,861 [INFO] parallelexecution      commited chunk: 51\n",
      "2023-12-15 14:46:55,863 [INFO] basedownloading      start to download 2010q1.zip \n",
      "2023-12-15 14:46:55,864 [INFO] basedownloading      start to download 2009q4.zip \n",
      "2023-12-15 14:46:55,869 [INFO] basedownloading      start to download 2009q3.zip \n",
      "2023-12-15 14:46:58,041 [INFO] parallelexecution      commited chunk: 54\n",
      "2023-12-15 14:46:58,045 [INFO] basedownloading      start to download 2009q2.zip \n",
      "2023-12-15 14:46:58,047 [INFO] basedownloading      start to download 2009q1.zip \n",
      "2023-12-15 14:46:58,618 [INFO] parallelexecution      commited chunk: 57\n",
      "2023-12-15 14:46:59,263 [INFO] updateprocess  start to transform to parquet format ...\n",
      "2023-12-15 14:46:59,274 [INFO] parallelexecution      items to process: 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rapid-api-key is set: \n",
      "If you are interested in daily updates, please have a look at https://rapidapi.com/hansjoerg.wingeier/api/daily-sec-financial-statement-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 14:46:59,371 [INFO] toparquettransforming  processing 2009q2.zip\n",
      "2023-12-15 14:46:59,376 [INFO] toparquettransforming  processing 2019q4.zip\n",
      "2023-12-15 14:46:59,385 [INFO] toparquettransforming  processing 2022q2.zip\n",
      "2023-12-15 14:46:59,400 [INFO] toparquettransforming  processing 2018q1.zip\n",
      "2023-12-15 14:47:00,552 [INFO] toparquettransforming  processing 2021q3.zip\n",
      "2023-12-15 14:47:23,640 [INFO] toparquettransforming  processing 2011q3.zip\n",
      "2023-12-15 14:47:26,986 [INFO] toparquettransforming  processing 2010q4.zip\n",
      "2023-12-15 14:47:28,728 [INFO] toparquettransforming  processing 2012q2.zip\n",
      "2023-12-15 14:47:29,642 [INFO] toparquettransforming  processing 2019q2.zip\n",
      "2023-12-15 14:47:32,945 [INFO] toparquettransforming  processing 2012q3.zip\n",
      "2023-12-15 14:47:48,827 [INFO] toparquettransforming  processing 2015q2.zip\n",
      "2023-12-15 14:47:54,025 [INFO] toparquettransforming  processing 2011q1.zip\n",
      "2023-12-15 14:48:00,566 [INFO] toparquettransforming  processing 2021q2.zip\n",
      "2023-12-15 14:48:01,487 [INFO] toparquettransforming  processing 2017q3.zip\n",
      "2023-12-15 14:48:10,445 [INFO] toparquettransforming  processing 2010q3.zip\n",
      "2023-12-15 14:48:16,740 [INFO] toparquettransforming  processing 2016q2.zip\n",
      "2023-12-15 14:48:20,520 [INFO] toparquettransforming  processing 2012q4.zip\n",
      "2023-12-15 14:48:32,705 [INFO] toparquettransforming  processing 2021q4.zip\n",
      "2023-12-15 14:48:39,474 [INFO] toparquettransforming  processing 2016q4.zip\n",
      "2023-12-15 14:48:52,592 [INFO] toparquettransforming  processing 2013q3.zip\n",
      "2023-12-15 14:49:05,408 [INFO] toparquettransforming  processing 2017q2.zip\n",
      "2023-12-15 14:49:11,445 [INFO] toparquettransforming  processing 2010q1.zip\n",
      "2023-12-15 14:49:11,770 [INFO] toparquettransforming  processing 2022q1.zip\n",
      "2023-12-15 14:49:13,114 [INFO] toparquettransforming  processing 2019q3.zip\n",
      "2023-12-15 14:49:30,903 [INFO] toparquettransforming  processing 2012q1.zip\n",
      "2023-12-15 14:49:33,383 [INFO] toparquettransforming  processing 2013q1.zip\n",
      "2023-12-15 14:49:44,634 [INFO] toparquettransforming  processing 2023q2.zip\n",
      "2023-12-15 14:49:58,430 [INFO] toparquettransforming  processing 2013q4.zip\n",
      "2023-12-15 14:50:10,166 [INFO] toparquettransforming  processing 2009q1.zip\n",
      "2023-12-15 14:50:10,475 [INFO] toparquettransforming  processing 2014q2.zip\n",
      "2023-12-15 14:50:20,539 [INFO] toparquettransforming  processing 2018q4.zip\n",
      "2023-12-15 14:50:24,472 [INFO] toparquettransforming  processing 2019q1.zip\n",
      "2023-12-15 14:50:32,441 [INFO] toparquettransforming  processing 2020q4.zip\n",
      "2023-12-15 14:50:43,171 [INFO] toparquettransforming  processing 2015q4.zip\n",
      "2023-12-15 14:50:45,087 [INFO] toparquettransforming  processing 2020q3.zip\n",
      "2023-12-15 14:50:57,762 [INFO] toparquettransforming  processing 2023q1.zip\n",
      "2023-12-15 14:51:01,679 [INFO] toparquettransforming  processing 2022q3.zip\n",
      "2023-12-15 14:51:13,530 [INFO] toparquettransforming  processing 2011q2.zip\n",
      "2023-12-15 14:51:14,518 [INFO] toparquettransforming  processing 2013q2.zip\n",
      "2023-12-15 14:51:18,146 [INFO] toparquettransforming  processing 2009q3.zip\n",
      "2023-12-15 14:51:19,386 [INFO] toparquettransforming  processing 2021q1.zip\n",
      "2023-12-15 14:51:33,376 [INFO] toparquettransforming  processing 2017q4.zip\n",
      "2023-12-15 14:51:36,807 [INFO] toparquettransforming  processing 2009q4.zip\n",
      "2023-12-15 14:51:39,591 [INFO] toparquettransforming  processing 2020q1.zip\n",
      "2023-12-15 14:51:51,356 [INFO] toparquettransforming  processing 2014q1.zip\n",
      "2023-12-15 14:51:56,728 [INFO] toparquettransforming  processing 2018q2.zip\n",
      "2023-12-15 14:52:03,702 [INFO] toparquettransforming  processing 2022q4.zip\n",
      "2023-12-15 14:52:15,812 [INFO] toparquettransforming  processing 2018q3.zip\n",
      "2023-12-15 14:52:27,163 [INFO] toparquettransforming  processing 2016q1.zip\n",
      "2023-12-15 14:52:36,455 [INFO] toparquettransforming  processing 2010q2.zip\n",
      "2023-12-15 14:52:39,435 [INFO] toparquettransforming  processing 2017q1.zip\n",
      "2023-12-15 14:52:42,610 [INFO] toparquettransforming  processing 2011q4.zip\n",
      "2023-12-15 14:52:44,953 [INFO] toparquettransforming  processing 2015q1.zip\n",
      "2023-12-15 14:53:06,905 [INFO] toparquettransforming  processing 2020q2.zip\n",
      "2023-12-15 14:53:12,475 [INFO] toparquettransforming  processing 2023q3.zip\n",
      "2023-12-15 14:53:20,605 [INFO] toparquettransforming  processing 2014q4.zip\n",
      "2023-12-15 14:53:25,991 [INFO] toparquettransforming  processing 2014q3.zip\n",
      "2023-12-15 14:53:33,577 [INFO] toparquettransforming  processing 2016q3.zip\n",
      "2023-12-15 14:54:00,143 [INFO] toparquettransforming  processing 2015q3.zip\n",
      "2023-12-15 14:54:10,203 [INFO] parallelexecution      commited chunk: 0\n",
      "2023-12-15 14:54:10,230 [INFO] updateprocess  start to index parquet files ...\n",
      "2023-12-15 14:54:10,625 [INFO] indexing  indexing file 2016q4.zip\n",
      "2023-12-15 14:54:12,864 [INFO] indexing  indexing file 2017q4.zip\n",
      "2023-12-15 14:54:13,317 [INFO] indexing  indexing file 2013q3.zip\n",
      "2023-12-15 14:54:13,993 [INFO] indexing  indexing file 2021q4.zip\n",
      "2023-12-15 14:54:16,466 [INFO] indexing  indexing file 2020q4.zip\n",
      "2023-12-15 14:54:17,403 [INFO] indexing  indexing file 2022q3.zip\n",
      "2023-12-15 14:54:18,350 [INFO] indexing  indexing file 2023q3.zip\n",
      "2023-12-15 14:54:19,484 [INFO] indexing  indexing file 2009q1.zip\n",
      "2023-12-15 14:54:19,603 [INFO] indexing  indexing file 2010q1.zip\n",
      "2023-12-15 14:54:20,190 [INFO] indexing  indexing file 2016q1.zip\n",
      "2023-12-15 14:54:21,088 [INFO] indexing  indexing file 2020q2.zip\n",
      "2023-12-15 14:54:22,076 [INFO] indexing  indexing file 2012q2.zip\n",
      "2023-12-15 14:54:23,391 [INFO] indexing  indexing file 2019q4.zip\n",
      "2023-12-15 14:54:24,732 [INFO] indexing  indexing file 2014q2.zip\n",
      "2023-12-15 14:54:25,925 [INFO] indexing  indexing file 2010q2.zip\n",
      "2023-12-15 14:54:26,589 [INFO] indexing  indexing file 2021q3.zip\n",
      "2023-12-15 14:54:28,317 [INFO] indexing  indexing file 2014q1.zip\n",
      "2023-12-15 14:54:29,624 [INFO] indexing  indexing file 2009q3.zip\n",
      "2023-12-15 14:54:30,242 [INFO] indexing  indexing file 2023q1.zip\n",
      "2023-12-15 14:54:31,954 [INFO] indexing  indexing file 2018q1.zip\n",
      "2023-12-15 14:54:34,164 [INFO] indexing  indexing file 2022q4.zip\n",
      "2023-12-15 14:54:36,026 [INFO] indexing  indexing file 2011q1.zip\n",
      "2023-12-15 14:54:37,195 [INFO] indexing  indexing file 2020q3.zip\n",
      "2023-12-15 14:54:39,014 [INFO] indexing  indexing file 2013q2.zip\n",
      "2023-12-15 14:54:41,073 [INFO] indexing  indexing file 2009q4.zip\n",
      "2023-12-15 14:54:41,645 [INFO] indexing  indexing file 2014q4.zip\n",
      "2023-12-15 14:54:44,724 [INFO] indexing  indexing file 2017q1.zip\n",
      "2023-12-15 14:54:46,561 [INFO] indexing  indexing file 2018q4.zip\n",
      "2023-12-15 14:54:48,753 [INFO] indexing  indexing file 2023q2.zip\n",
      "2023-12-15 14:54:50,908 [INFO] indexing  indexing file 2017q3.zip\n",
      "2023-12-15 14:54:53,293 [INFO] indexing  indexing file 2019q1.zip\n",
      "2023-12-15 14:54:55,516 [INFO] indexing  indexing file 2020q1.zip\n",
      "2023-12-15 14:54:57,733 [INFO] indexing  indexing file 2011q4.zip\n",
      "2023-12-15 14:55:00,113 [INFO] indexing  indexing file 2022q2.zip\n",
      "2023-12-15 14:55:08,693 [INFO] indexing  indexing file 2019q3.zip\n",
      "2023-12-15 14:55:14,626 [INFO] indexing  indexing file 2021q1.zip\n",
      "2023-12-15 14:55:19,053 [INFO] indexing  indexing file 2015q4.zip\n",
      "2023-12-15 14:55:21,958 [INFO] indexing  indexing file 2009q2.zip\n",
      "2023-12-15 14:55:22,311 [INFO] indexing  indexing file 2014q3.zip\n",
      "2023-12-15 14:55:25,231 [INFO] indexing  indexing file 2015q3.zip\n",
      "2023-12-15 14:55:28,110 [INFO] indexing  indexing file 2016q3.zip\n",
      "2023-12-15 14:55:30,825 [INFO] indexing  indexing file 2016q2.zip\n",
      "2023-12-15 14:55:36,096 [INFO] indexing  indexing file 2010q3.zip\n",
      "2023-12-15 14:55:37,080 [INFO] indexing  indexing file 2017q2.zip\n",
      "2023-12-15 14:55:41,243 [INFO] indexing  indexing file 2015q1.zip\n",
      "2023-12-15 14:55:44,195 [INFO] indexing  indexing file 2018q3.zip\n",
      "2023-12-15 14:55:47,167 [INFO] indexing  indexing file 2011q2.zip\n",
      "2023-12-15 14:55:48,781 [INFO] indexing  indexing file 2012q4.zip\n",
      "2023-12-15 14:55:52,812 [INFO] indexing  indexing file 2011q3.zip\n",
      "2023-12-15 14:55:55,216 [INFO] indexing  indexing file 2021q2.zip\n",
      "2023-12-15 14:55:58,506 [INFO] indexing  indexing file 2010q4.zip\n",
      "2023-12-15 14:55:59,574 [INFO] indexing  indexing file 2022q1.zip\n",
      "2023-12-15 14:56:03,501 [INFO] indexing  indexing file 2013q4.zip\n",
      "2023-12-15 14:56:06,862 [INFO] indexing  indexing file 2012q3.zip\n",
      "2023-12-15 14:56:10,065 [INFO] indexing  indexing file 2012q1.zip\n",
      "2023-12-15 14:56:12,881 [INFO] indexing  indexing file 2018q2.zip\n",
      "2023-12-15 14:56:16,147 [INFO] indexing  indexing file 2013q1.zip\n",
      "2023-12-15 14:56:19,413 [INFO] indexing  indexing file 2019q2.zip\n",
      "2023-12-15 14:56:22,591 [INFO] indexing  indexing file 2015q2.zip\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.update import update\n",
    "\n",
    "update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab10736-1898-4110-9ee3-c51d59206748",
   "metadata": {},
   "source": [
    "The following tasks will be executed:\n",
    "1. All currently available zip-files are downloaded form sec.gov (these are over 50 files that will need over 2 GB of space on your local drive)\n",
    "2. All the zipfiles are transformed and stored as parquet files. Per default, the zipfile is deleted afterwards. If you want to keep the zip files, set the parameter 'KeepZipFiles' in the config file to True.\n",
    "3. An index inside a sqlite db file is created\n",
    "\n",
    "This may take a few minutes.\n",
    "\n",
    "If you don't call update \"manually\", then the first time you call a function from the library, a download will be triggered.\n",
    "\n",
    "Moreover, at most once a day, it is checked if there is a new zip file available on sec.gov. If there is, a download will be started automatically. \n",
    "If you don't want 'auto-update', set the 'AutoUpdate' in your config file to False.\n",
    "The new quarter zip files are available by the beginning of every quarter (January, April, July, October), hence, yo have to run the update() at the beginning of every quarter to get the data for the reprots from last quarter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d4c466-3431-48b7-b2c8-b8fe68710110",
   "metadata": {},
   "source": [
    "Note: the first time downloading data will take a couple of minutes, since over 2 GB of data will be downloaded and converted into parquet format.\n",
    "\n",
    "Note: **If you plan to use Jupyter, make sure that you configure the directories at a location where your Jupyter process has access. The used default directory (your user home directory) will work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ca848-83a3-408a-9259-f534638be908",
   "metadata": {},
   "source": [
    "## A first simple example\n",
    "Goal: present the information in the balance sheet of Apple's 2022 10-K report in the same way as it appears in the\n",
    "original report on page 31 (\"CONSOLIDATED BALANCE SHEETS\"): https://www.sec.gov/ix?doc=/Archives/edgar/data/320193/000032019322000108/aapl-20220924.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bddd29-a291-4ea8-ab70-0d7a4fb9c4af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 14:59:44,758 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    adsh coreg  \\\n",
      "0   0000320193-22-000108         \n",
      "1   0000320193-22-000108         \n",
      "2   0000320193-22-000108         \n",
      "3   0000320193-22-000108         \n",
      "4   0000320193-22-000108         \n",
      "5   0000320193-22-000108         \n",
      "6   0000320193-22-000108         \n",
      "7   0000320193-22-000108         \n",
      "8   0000320193-22-000108         \n",
      "9   0000320193-22-000108         \n",
      "10  0000320193-22-000108         \n",
      "11  0000320193-22-000108         \n",
      "12  0000320193-22-000108         \n",
      "13  0000320193-22-000108         \n",
      "14  0000320193-22-000108         \n",
      "15  0000320193-22-000108         \n",
      "16  0000320193-22-000108         \n",
      "17  0000320193-22-000108         \n",
      "18  0000320193-22-000108         \n",
      "19  0000320193-22-000108         \n",
      "20  0000320193-22-000108         \n",
      "21  0000320193-22-000108         \n",
      "22  0000320193-22-000108         \n",
      "23  0000320193-22-000108         \n",
      "24  0000320193-22-000108         \n",
      "25  0000320193-22-000108         \n",
      "26  0000320193-22-000108         \n",
      "27  0000320193-22-000108         \n",
      "28  0000320193-22-000108         \n",
      "29  0000320193-22-000108         \n",
      "30  0000320193-22-000108         \n",
      "\n",
      "                                                tag       version stmt  \\\n",
      "0             CashAndCashEquivalentsAtCarryingValue  us-gaap/2022   BS   \n",
      "1                       MarketableSecuritiesCurrent  us-gaap/2022   BS   \n",
      "2                      AccountsReceivableNetCurrent  us-gaap/2022   BS   \n",
      "3                                      InventoryNet  us-gaap/2022   BS   \n",
      "4                        NontradeReceivablesCurrent  us-gaap/2022   BS   \n",
      "5                                OtherAssetsCurrent  us-gaap/2022   BS   \n",
      "6                                     AssetsCurrent  us-gaap/2022   BS   \n",
      "7                    MarketableSecuritiesNoncurrent  us-gaap/2022   BS   \n",
      "8                      PropertyPlantAndEquipmentNet  us-gaap/2022   BS   \n",
      "9                             OtherAssetsNoncurrent  us-gaap/2022   BS   \n",
      "10                                 AssetsNoncurrent  us-gaap/2022   BS   \n",
      "11                                           Assets  us-gaap/2022   BS   \n",
      "12                           AccountsPayableCurrent  us-gaap/2022   BS   \n",
      "13                          OtherLiabilitiesCurrent  us-gaap/2022   BS   \n",
      "14             ContractWithCustomerLiabilityCurrent  us-gaap/2022   BS   \n",
      "15                                  CommercialPaper  us-gaap/2022   BS   \n",
      "16                              LongTermDebtCurrent  us-gaap/2022   BS   \n",
      "17                               LiabilitiesCurrent  us-gaap/2022   BS   \n",
      "18                           LongTermDebtNoncurrent  us-gaap/2022   BS   \n",
      "19                       OtherLiabilitiesNoncurrent  us-gaap/2022   BS   \n",
      "20                            LiabilitiesNoncurrent  us-gaap/2022   BS   \n",
      "21                                      Liabilities  us-gaap/2022   BS   \n",
      "22     CommonStocksIncludingAdditionalPaidInCapital  us-gaap/2022   BS   \n",
      "23               RetainedEarningsAccumulatedDeficit  us-gaap/2022   BS   \n",
      "24  AccumulatedOtherComprehensiveIncomeLossNetOfTax  us-gaap/2022   BS   \n",
      "25                               StockholdersEquity  us-gaap/2022   BS   \n",
      "26                 LiabilitiesAndStockholdersEquity  us-gaap/2022   BS   \n",
      "27              CommonStockParOrStatedValuePerShare  us-gaap/2022   BS   \n",
      "28                      CommonStockSharesAuthorized  us-gaap/2022   BS   \n",
      "29                          CommonStockSharesIssued  us-gaap/2022   BS   \n",
      "30                     CommonStockSharesOutstanding  us-gaap/2022   BS   \n",
      "\n",
      "    report  line     uom  negating  inpth      20220930      20210930  \n",
      "0        5     3     USD         0      0  2.364600e+10  3.494000e+10  \n",
      "1        5     4     USD         0      0  2.465800e+10  2.769900e+10  \n",
      "2        5     5     USD         0      0  2.818400e+10  2.627800e+10  \n",
      "3        5     6     USD         0      0  4.946000e+09  6.580000e+09  \n",
      "4        5     7     USD         0      0  3.274800e+10  2.522800e+10  \n",
      "5        5     8     USD         0      0  2.122300e+10  1.411100e+10  \n",
      "6        5     9     USD         0      0  1.354050e+11  1.348360e+11  \n",
      "7        5    11     USD         0      0  1.208050e+11  1.278770e+11  \n",
      "8        5    12     USD         0      0  4.211700e+10  3.944000e+10  \n",
      "9        5    13     USD         0      0  5.442800e+10  4.884900e+10  \n",
      "10       5    14     USD         0      0  2.173500e+11  2.161660e+11  \n",
      "11       5    15     USD         0      0  3.527550e+11  3.510020e+11  \n",
      "12       5    18     USD         0      0  6.411500e+10  5.476300e+10  \n",
      "13       5    19     USD         0      0  6.084500e+10  4.749300e+10  \n",
      "14       5    20     USD         0      0  7.912000e+09  7.612000e+09  \n",
      "15       5    21     USD         0      0  9.982000e+09  6.000000e+09  \n",
      "16       5    22     USD         0      0  1.112800e+10  9.613000e+09  \n",
      "17       5    23     USD         0      0  1.539820e+11  1.254810e+11  \n",
      "18       5    25     USD         0      0  9.895900e+10  1.091060e+11  \n",
      "19       5    26     USD         0      0  4.914200e+10  5.332500e+10  \n",
      "20       5    27     USD         0      0  1.481010e+11  1.624310e+11  \n",
      "21       5    28     USD         0      0  3.020830e+11  2.879120e+11  \n",
      "22       5    31     USD         0      0  6.484900e+10  5.736500e+10  \n",
      "23       5    32     USD         0      0 -3.068000e+09  5.562000e+09  \n",
      "24       5    33     USD         0      0 -1.110900e+10  1.630000e+08  \n",
      "25       5    34     USD         0      0  5.067200e+10  6.309000e+10  \n",
      "26       5    35     USD         0      0  3.527550e+11  3.510020e+11  \n",
      "27       6     1     USD         0      1  0.000000e+00  0.000000e+00  \n",
      "28       6     2  shares         0      1  5.040000e+10  5.040000e+10  \n",
      "29       6     3  shares         0      1  1.594342e+10  1.642679e+10  \n",
      "30       6     4  shares         0      1  1.594342e+10  1.642679e+10  \n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.reportcollecting import SingleReportCollector\n",
    "from secfsdstools.e_filter.rawfiltering import ReportPeriodAndPreviousPeriodRawFilter\n",
    "from secfsdstools.e_presenter.presenting import StandardStatementPresenter\n",
    "\n",
    "# the unique identifier for apple's 10-K report of 2022\n",
    "apple_10k_2022_adsh = \"0000320193-22-000108\"\n",
    "\n",
    "# us a Collector to grab the data of the 10-K report. filter for balancesheet information\n",
    "collector: SingleReportCollector = SingleReportCollector.get_report_by_adsh(\n",
    "      adsh=apple_10k_2022_adsh,\n",
    "      stmt_filter=[\"BS\"]\n",
    ")  \n",
    "rawdatabag = collector.collect() # load the data from the disk\n",
    "  \n",
    "bs_df = (rawdatabag\n",
    "         # ensure only data from the period (2022) of the previous period (2021) is in the data\n",
    "         .filter(ReportPeriodAndPreviousPeriodRawFilter())\n",
    "         # join the the content of the pre_txt and num_txt together\n",
    "         .join()  \n",
    "         # format the data in the same way as it appears in the report\n",
    "         .present(StandardStatementPresenter())) \n",
    "print(bs_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c75f3-bcdf-445f-bf8b-6094215da914",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The following diagram gives an overview on SECFSDSTools library.\n",
    "\n",
    "![Overview](https://github.com/HansjoergW/sec-fincancial-statement-data-set/raw/main/docs/images/overview.png)\n",
    "\n",
    "It mainly exists out of two main processes. The first one ist the \"Date Update Process\" wich is responsible for the\n",
    "download of the Financial Statement Data Sets zip files from the sec.gov website, transforming the content into parquet\n",
    "format, and indexing the content of these files in a simple SQLite database. Again, this whole process can be started\n",
    "\"manually\" by calling the update method, or it is done automatically, as it is described above.\n",
    "\n",
    "The second main process is the \"Data Processing Process\", which is working with the data that is stored inside the\n",
    "sub.txt, pre.txt, and num.txt files from the zip files. The \"Data Processing Process\" mainly exists out of four steps:\n",
    "\n",
    "* **Collect** <br/> Collect the rawdata from one or more different zip files. For instance, get all the data for a single\n",
    "report, or get the data for all 10-K reports of a single report from several zip files.\n",
    "* **Raw Processing** <br/> Once the data is collected, the collected data for sub.txt, pre.txt, and num.txt is available\n",
    "as a pandas dataframe. Filters can be applied, the content can directly be saved and loaded.\n",
    "* **Joined Processing** <br/> From the \"Raw Data\", a \"joined\" representation can be created. This joins the data from\n",
    "the pre.txt and num.txt content together based on the \"adhs\", \"tag\", and \"version\" attributes. \"Joined data\" can also be\n",
    "filtered, concatenated, directly saved and loaded.\n",
    "* **Present** <br/> Produce a single pandas dataframe out of the data and use it for further processing.\n",
    "\n",
    "The diagramm also shows the main classes with which a user interacts. The use of them  is described in the following chapters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3354a79-cd7c-4e22-bf7f-035d0ecd7c04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General\n",
    "Most of the classes you can interact with have a factory method which name starts with \"get_\". All this factory method\n",
    "take at least one **optional** parameter called configuration which is of type \"Configuration\".\n",
    "\n",
    "If you do not provide this parameter, the class will read the configuration info from you configuration file in your home\n",
    "directory. If, for whatever reason, you do want to provide an alternative configuration, you can overwrite it.\n",
    "\n",
    "However, normally you do not have to provide the \"configuration\" parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc9b97-5209-404d-bb19-42d338bc5c71",
   "metadata": {},
   "source": [
    "## Index: working with the index\n",
    "The first class that interacts with the index is the `IndexSearch` class. It provides a single method `find_company_by_name`\n",
    "which executes a SQL Like search on the name of the available companies and returns a pandas dataframe with the columns\n",
    "'name' and 'cik' (the central index key, or the unique id of a company in the financial statements data sets).\n",
    "The main purpose of this class is to find the cik for a company (of course, you can also directly search the cik on https://www.sec.gov/edgar/searchedgar/companysearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4569625-869b-4112-bde1-6dcb70b517d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:00:33,207 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             name      cik\n",
      "0       APPLE GREEN HOLDING, INC.  1510976\n",
      "1    APPLE HOSPITALITY REIT, INC.  1418121\n",
      "2                       APPLE INC   320193\n",
      "3       APPLE ISPORTS GROUP, INC.  1134982\n",
      "4          APPLE REIT EIGHT, INC.  1387361\n",
      "5           APPLE REIT NINE, INC.  1418121\n",
      "6          APPLE REIT SEVEN, INC.  1329011\n",
      "7              APPLE REIT SIX INC  1277151\n",
      "8            APPLE REIT TEN, INC.  1498864\n",
      "9          APPLETON PAPERS INC/WI  1144326\n",
      "10  DR PEPPER SNAPPLE GROUP, INC.  1418135\n",
      "11   MAUI LAND & PINEAPPLE CO INC    63330\n",
      "12          PINEAPPLE ENERGY INC.    22701\n",
      "13  PINEAPPLE EXPRESS CANNABIS CO  1710495\n",
      "14        PINEAPPLE EXPRESS, INC.  1654672\n",
      "15       PINEAPPLE HOLDINGS, INC.    22701\n",
      "16                PINEAPPLE, INC.  1654672\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.c_index.searching import IndexSearch\n",
    "\n",
    "index_search = IndexSearch.get_index_search()\n",
    "results = index_search.find_company_by_name(\"apple\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dd41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLOBANT S.A.</td>\n",
       "      <td>1557860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name      cik\n",
       "0  GLOBANT S.A.  1557860"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_search.find_company_by_name(\"globant\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e0584-599f-4684-ab22-66bd790151d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once you have the cik of a company, you can use the `CompanyIndexReader` to get information on available reports of a company.\n",
    "To get an instance of the class, you use the get `get_company_index_reader` method and provide the cik parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5033f87-b67f-47cf-99f1-8fd527000fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:05:45,326 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.c_index.companyindexreading import CompanyIndexReader\n",
    "\n",
    "apple_cik = 320193\n",
    "apple_index_reader = CompanyIndexReader.get_company_index_reader(cik=apple_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894c223-3652-432a-a82a-693896a5cf90",
   "metadata": {},
   "source": [
    "First, you could use the method `get_latest_company_filing` which returns a dictionary with the latest filing of the company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92223bf-6589-4eba-ba22-d2596b47bbd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adsh': '0000320193-23-000075', 'cik': 320193, 'name': 'APPLE INC', 'sic': 3571.0, 'countryba': 'US', 'stprba': 'CA', 'cityba': 'CUPERTINO', 'zipba': '95014', 'bas1': 'ONE APPLE PARK WAY', 'bas2': None, 'baph': '(408) 996-1010', 'countryma': 'US', 'stprma': 'CA', 'cityma': 'CUPERTINO', 'zipma': '95014', 'mas1': 'ONE APPLE PARK WAY', 'mas2': None, 'countryinc': 'US', 'stprinc': 'CA', 'ein': 942404110, 'former': 'APPLE INC', 'changed': 20070109.0, 'afs': '1-LAF', 'wksi': 0, 'fye': '0930', 'form': '8-K', 'period': 20230731, 'fy': nan, 'fp': None, 'filed': 20230803, 'accepted': '2023-08-03 16:30:00.0', 'prevrpt': 0, 'detail': 0, 'instance': 'aapl-20230803_htm.xml', 'nciks': 1, 'aciks': None}\n"
     ]
    }
   ],
   "source": [
    "print(apple_index_reader.get_latest_company_filing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ab77d-c444-41ca-8ece-dad1054caf19",
   "metadata": {},
   "source": [
    "Next there are two methods which return the metadata of the reports that a company has filed. The result is either\n",
    "returned as a list of `IndexReport` instances, if you use the method `get_all_company_reports` or as pandas dataframe if\n",
    "you use the method `get_all_company_reports_df`. Both method can take an optional parameter forms, which defines the\n",
    "type of the report that shall be returned. For instance, if you are only interested in the annual and quarterly report,\n",
    "set forms to `[\"10-K\", \"10-Q\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a6233a0-7543-43be-a581-8ed279787442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    adsh     cik       name  form     filed    period  \\\n",
      "0   0000320193-22-000108  320193  APPLE INC  10-K  20221028  20220930   \n",
      "1   0000320193-21-000105  320193  APPLE INC  10-K  20211029  20210930   \n",
      "2   0000320193-20-000096  320193  APPLE INC  10-K  20201030  20200930   \n",
      "3   0000320193-19-000119  320193  APPLE INC  10-K  20191031  20190930   \n",
      "4   0000320193-18-000145  320193  APPLE INC  10-K  20181105  20180930   \n",
      "5   0000320193-17-000070  320193  APPLE INC  10-K  20171103  20170930   \n",
      "6   0001628280-16-020309  320193  APPLE INC  10-K  20161026  20160930   \n",
      "7   0001193125-15-356351  320193  APPLE INC  10-K  20151028  20150930   \n",
      "8   0001193125-14-383437  320193  APPLE INC  10-K  20141027  20140930   \n",
      "9   0001193125-13-416534  320193  APPLE INC  10-K  20131030  20130930   \n",
      "10  0001193125-12-444068  320193  APPLE INC  10-K  20121031  20120930   \n",
      "11  0001193125-11-282113  320193  APPLE INC  10-K  20111026  20110930   \n",
      "12  0001193125-10-238044  320193  APPLE INC  10-K  20101027  20100930   \n",
      "13  0001193125-09-214859  320193  APPLE INC  10-K  20091027  20090930   \n",
      "\n",
      "                                             fullPath  originFile  \\\n",
      "0   /home/sebacastillo/genai0/data/parquet/quarter...  2022q4.zip   \n",
      "1   /home/sebacastillo/genai0/data/parquet/quarter...  2021q4.zip   \n",
      "2   /home/sebacastillo/genai0/data/parquet/quarter...  2020q4.zip   \n",
      "3   /home/sebacastillo/genai0/data/parquet/quarter...  2019q4.zip   \n",
      "4   /home/sebacastillo/genai0/data/parquet/quarter...  2018q4.zip   \n",
      "5   /home/sebacastillo/genai0/data/parquet/quarter...  2017q4.zip   \n",
      "6   /home/sebacastillo/genai0/data/parquet/quarter...  2016q4.zip   \n",
      "7   /home/sebacastillo/genai0/data/parquet/quarter...  2015q4.zip   \n",
      "8   /home/sebacastillo/genai0/data/parquet/quarter...  2014q4.zip   \n",
      "9   /home/sebacastillo/genai0/data/parquet/quarter...  2013q4.zip   \n",
      "10  /home/sebacastillo/genai0/data/parquet/quarter...  2012q4.zip   \n",
      "11  /home/sebacastillo/genai0/data/parquet/quarter...  2011q4.zip   \n",
      "12  /home/sebacastillo/genai0/data/parquet/quarter...  2010q4.zip   \n",
      "13  /home/sebacastillo/genai0/data/parquet/quarter...  2009q4.zip   \n",
      "\n",
      "   originFileType                                                url  \n",
      "0         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "1         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "2         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "3         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "4         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "5         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "6         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "7         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "8         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "9         quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "10        quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "11        quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "12        quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "13        quarter  https://www.sec.gov/Archives/edgar/data/320193...  \n"
     ]
    }
   ],
   "source": [
    "# only show the annual reports of apple\n",
    "print(apple_index_reader.get_all_company_reports_df(forms=[\"10-K\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf84f13-469d-42d3-9098-40707373c6d8",
   "metadata": {},
   "source": [
    "Note: the entries in the url column above directly open the filing of that report on the sec.gov website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01caac-c8a4-416c-a6f2-42acc79a22bd",
   "metadata": {},
   "source": [
    "## Collect: collecting the data for reports\n",
    "The previously introduced `IndexSearch` and `CompanyIndexReader` let you know what data is available, but they do not\n",
    "return the real data of the financial statements. This is what the `Collector` classes are used for.\n",
    "\n",
    "All the `Collector` classes have their own factory method(s) which instantiates the class. Most of these factory methods\n",
    "also provide parameters to filter the data directly when being loaded from the parquet files.\n",
    "These are\n",
    "* the `forms_filter` <br> lets you select which report type should be loaded (e.g. \"10-K\" or \"10-Q\").<br>\n",
    "  Note: the fomrs filter affects all dataframes (sub, pre, num).\n",
    "* the `stmt_filter` <br> defines the statements that should be loaded (e.g., \"BS\" if only \"Balance Sheet\" data should be loaded) <br>\n",
    "  Note: the stmt filter only affects the pre dataframe.\n",
    "* the `tag_filter` <br> defines the tags, that should be loaded (e.g., \"Assets\" if only the \"Assets\" tag should be loaded) <br>\n",
    "  Note: the tag filter affects the pre and num dataframes.\n",
    "\n",
    "It is also possible to apply filter for these attributes after the data is loaded, but since the `Collector` classes\n",
    "apply this filters directly during the load process from the parquet files (which means that fewer data is loaded from\n",
    "the disk) this is generally more efficient.\n",
    "\n",
    "All `Collector` classes have a `collect` method which then loads the data from the parquet files and returns an instance\n",
    "of `RawDataBag`. The `RawDataBag` instance contains then a pandas dataframe for the `sub` (subscription) data,\n",
    "`pre` (presentation) data, and `num` (the numeric values) data.\n",
    "\n",
    "The framework provides the following collectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1af938-7189-471f-9bcf-6e79be23cb45",
   "metadata": {},
   "source": [
    "---\n",
    "* `SingleReportCollector` <br> As the name suggests, this `Collector` returns the data of a single report. It is \n",
    "  instantiated by providing the `adsh` of the desired report as parameter of the `get_report_by_adsh` factory method, \n",
    "  or by using an instance of the `IndexReport` as parameter of the `get_report_by_indexreport`. (As a reminder: \n",
    "  instances of `IndexReport` are returned by the `CompanyIndexReader` class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc2ff08-5070-49da-a99d-1bbe12c1c3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:07:12,854 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   adsh     cik       name     sic countryba stprba  \\\n",
      "0  0000320193-22-000108  320193  APPLE INC  3571.0        US     CA   \n",
      "\n",
      "      cityba  zipba                bas1  bas2  ...    period      fy  fp  \\\n",
      "0  CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20220930  2022.0  FY   \n",
      "\n",
      "      filed               accepted prevrpt detail               instance  \\\n",
      "0  20221028  2022-10-27 18:01:00.0       0      1  aapl-20220924_htm.xml   \n",
      "\n",
      "  nciks  aciks  \n",
      "0     1   None  \n",
      "\n",
      "[1 rows x 36 columns] \n",
      "\n",
      "(185, 10)\n",
      "(503, 9)\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.reportcollecting import SingleReportCollector\n",
    "\n",
    "apple_10k_2022_adsh = \"0000320193-22-000108\"\n",
    "\n",
    "collector: SingleReportCollector = SingleReportCollector.get_report_by_adsh(adsh=apple_10k_2022_adsh)\n",
    "rawdatabag = collector.collect()\n",
    "\n",
    "# as expected, there is just one entry in the submission dataframe\n",
    "print(rawdatabag.sub_df, '\\n')\n",
    "\n",
    "# just print the size of the pre and num dataframes\n",
    "print(rawdatabag.pre_df.shape)\n",
    "print(rawdatabag.num_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b3e86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adsh</th>\n",
       "      <th>report</th>\n",
       "      <th>line</th>\n",
       "      <th>stmt</th>\n",
       "      <th>inpth</th>\n",
       "      <th>rfile</th>\n",
       "      <th>tag</th>\n",
       "      <th>version</th>\n",
       "      <th>plabel</th>\n",
       "      <th>negating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>AmendmentFlag</td>\n",
       "      <td>dei/2022</td>\n",
       "      <td>Amendment Flag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>CityAreaCode</td>\n",
       "      <td>dei/2022</td>\n",
       "      <td>City Area Code</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>CurrentFiscalYearEndDate</td>\n",
       "      <td>dei/2022</td>\n",
       "      <td>Current Fiscal Year End Date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>DocumentAnnualReport</td>\n",
       "      <td>dei/2022</td>\n",
       "      <td>Document Annual Report</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>DocumentFiscalPeriodFocus</td>\n",
       "      <td>dei/2022</td>\n",
       "      <td>Document Fiscal Period Focus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>A3.050NotesDue2029Member</td>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>3.050% Notes due 2029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>CP</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>A3.600NotesDue2042Member</td>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>3.600% Notes due 2042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>OtherComprehensiveIncomeLossDerivativeInstrume...</td>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>Total change in unrealized gains/losses on der...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>OtherComprehensiveIncomeLossDerivativeInstrume...</td>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>Change in fair value of derivative instruments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>OtherComprehensiveIncomeLossDerivativeInstrume...</td>\n",
       "      <td>0000320193-22-000108</td>\n",
       "      <td>Adjustment for net (gains)/losses realized and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adsh  report  line stmt  inpth rfile  \\\n",
       "0    0000320193-22-000108       1    46   CP      0     H   \n",
       "1    0000320193-22-000108       1    29   CP      0     H   \n",
       "2    0000320193-22-000108       1    18   CP      0     H   \n",
       "3    0000320193-22-000108       1    17   CP      0     H   \n",
       "4    0000320193-22-000108       1    48   CP      0     H   \n",
       "..                    ...     ...   ...  ...    ...   ...   \n",
       "180  0000320193-22-000108       1    12   CP      0     H   \n",
       "181  0000320193-22-000108       1    14   CP      0     H   \n",
       "182  0000320193-22-000108       4     7   CI      0     H   \n",
       "183  0000320193-22-000108       4     5   CI      0     H   \n",
       "184  0000320193-22-000108       4     6   CI      0     H   \n",
       "\n",
       "                                                   tag               version  \\\n",
       "0                                        AmendmentFlag              dei/2022   \n",
       "1                                         CityAreaCode              dei/2022   \n",
       "2                             CurrentFiscalYearEndDate              dei/2022   \n",
       "3                                 DocumentAnnualReport              dei/2022   \n",
       "4                            DocumentFiscalPeriodFocus              dei/2022   \n",
       "..                                                 ...                   ...   \n",
       "180                           A3.050NotesDue2029Member  0000320193-22-000108   \n",
       "181                           A3.600NotesDue2042Member  0000320193-22-000108   \n",
       "182  OtherComprehensiveIncomeLossDerivativeInstrume...  0000320193-22-000108   \n",
       "183  OtherComprehensiveIncomeLossDerivativeInstrume...  0000320193-22-000108   \n",
       "184  OtherComprehensiveIncomeLossDerivativeInstrume...  0000320193-22-000108   \n",
       "\n",
       "                                                plabel  negating  \n",
       "0                                       Amendment Flag         0  \n",
       "1                                       City Area Code         0  \n",
       "2                         Current Fiscal Year End Date         0  \n",
       "3                               Document Annual Report         0  \n",
       "4                         Document Fiscal Period Focus         0  \n",
       "..                                                 ...       ...  \n",
       "180                              3.050% Notes due 2029         0  \n",
       "181                              3.600% Notes due 2042         0  \n",
       "182  Total change in unrealized gains/losses on der...         0  \n",
       "183     Change in fair value of derivative instruments         0  \n",
       "184  Adjustment for net (gains)/losses realized and...         1  \n",
       "\n",
       "[185 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdatabag.pre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815f6ed-bb29-4fca-a036-1d63dd725282",
   "metadata": {},
   "source": [
    "---\n",
    "* `MultiReportCollector` <br> Contrary to the `SingleReportCollector`, this `Collector` can collect data from several\n",
    "  reports. Moreover, the data of the reports are loaded in parallel, this  especially improves the performance if the\n",
    "  reports are from different quarters (resp. are in different zip files). The class provides the factory methods \n",
    "  `get_reports_by_adshs` and `get_reports_by_indexreports`. The first takes a list of adsh strings, the second a list\n",
    "  of `IndexReport` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c60929-bbe5-4c8f-86a3-a5f72d640fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:07:54,210 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n",
      "2023-12-15 15:07:54,212 [INFO] parallelexecution      items to process: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000320193-22-000108\n",
      "0001193125-12-444068\n",
      "0000320193-21-0001050000320193-20-0000960000320193-19-000119\n",
      "0000320193-22-000108\n",
      "\n",
      "\n",
      "0000320193-18-000145\n",
      "0000320193-17-000070\n",
      "0001628280-16-020309\n",
      "0001193125-15-356351\n",
      "0001193125-14-383437\n",
      "0001193125-13-416534\n",
      "0001193125-12-444068\n",
      "0001193125-11-282113\n",
      "0001193125-10-238044\n",
      "0001193125-09-214859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:07:57,130 [INFO] parallelexecution      commited chunk: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   adsh     cik       name     sic countryba stprba  \\\n",
      "0  0000320193-22-000108  320193  APPLE INC  3571.0        US     CA   \n",
      "1  0001193125-12-444068  320193  APPLE INC  3571.0        US     CA   \n",
      "\n",
      "      cityba  zipba                bas1  bas2  ...    period      fy  fp  \\\n",
      "0  CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20220930  2022.0  FY   \n",
      "1  CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20120930  2012.0  FY   \n",
      "\n",
      "      filed               accepted prevrpt detail               instance  \\\n",
      "0  20221028  2022-10-27 18:01:00.0       0      1  aapl-20220924_htm.xml   \n",
      "1  20121031  2012-10-31 17:07:00.0       0      1      aapl-20120929.xml   \n",
      "\n",
      "  nciks  aciks  \n",
      "0     1   None  \n",
      "1     1   None  \n",
      "\n",
      "[2 rows x 36 columns] \n",
      "\n",
      "                   adsh     tag       version coreg     ddate  qtrs  uom  \\\n",
      "0  0000320193-22-000108  Assets  us-gaap/2022        20210930     0  USD   \n",
      "1  0000320193-22-000108  Assets  us-gaap/2022        20220930     0  USD   \n",
      "2  0001193125-12-444068  Assets  us-gaap/2012        20110930     0  USD   \n",
      "3  0001193125-12-444068  Assets  us-gaap/2012        20120930     0  USD   \n",
      "\n",
      "          value footnote  \n",
      "0  3.510020e+11     None  \n",
      "1  3.527550e+11     None  \n",
      "2  1.163710e+11     None  \n",
      "3  1.760640e+11     None  \n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.multireportcollecting import MultiReportCollector\n",
    "apple_10k_2022_adsh = \"0000320193-22-000108\"\n",
    "apple_10k_2012_adsh = \"0001193125-12-444068\"\n",
    "\n",
    "# load only the assets tags that are present in the 10-K report of apple in the years\n",
    "# 2022 and 2012\n",
    "collector: MultiReportCollector = MultiReportCollector.get_reports_by_adshs(\n",
    "                                              adshs=[apple_10k_2022_adsh, apple_10k_2012_adsh],\n",
    "                                              tag_filter=['Assets'])\n",
    "rawdatabag = collector.collect()\n",
    "# as expected, there are just two entries in the submission dataframe\n",
    "print(rawdatabag.sub_df, '\\n')\n",
    "print(rawdatabag.num_df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a68a5-170d-45f9-865b-fa1f8087a677",
   "metadata": {},
   "source": [
    "---\n",
    "* `ZipCollector` <br> This `Collector` collects the data of one single zip (resp. the folder that contains the parquet\n",
    "  files of this zip file). And since the original zip file contains the data for one quarter, the name you provide\n",
    "  in the `get_zuip_by_name` factory method reflects the quarter which data you want to load: e.g. `2022q1.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77f7c553-695f-4006-8026-97df10d4bf30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:08:02,623 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n",
      "2023-12-15 15:08:02,625 [INFO] parallelexecution      items to process: 1\n",
      "2023-12-15 15:08:02,626 [INFO] zipcollecting  processing /home/sebacastillo/genai0/data/parquet/quarter/2022q1.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:08:07,957 [INFO] parallelexecution      commited chunk: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4875, 36)\n",
      "(232863, 10)\n",
      "(2404949, 9)\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.zipcollecting import ZipCollector\n",
    "\n",
    "# only collect the Balance Sheet of annual reports that\n",
    "# were filed during the first quarter in 2022\n",
    "collector: ZipCollector = ZipCollector.get_zip_by_name(name=\"2022q1.zip\",\n",
    "                                                       forms_filter=[\"10-K\"],\n",
    "                                                       stmt_filter=[\"BS\"])\n",
    "\n",
    "rawdatabag = collector.collect()\n",
    "\n",
    "# only show the size of the data frame\n",
    "# .. over 4000 companies filed a 10 K report in q1 2022\n",
    "print(rawdatabag.sub_df.shape)\n",
    "print(rawdatabag.pre_df.shape)\n",
    "print(rawdatabag.num_df.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ba431-fad6-4d58-ba4b-de3c9f837d5f",
   "metadata": {},
   "source": [
    "---\n",
    "* `CompanyReportCollector` <br> This class returns reports for one or more companies. The factory method \n",
    "  `get_company_collector` provides the parameter `ciks` which takes a list of cik numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77165def-b05c-4713-bc86-02e7732fd35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:08:12,253 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:08:15,741 [INFO] parallelexecution      items to process: 14\n",
      "2023-12-15 15:08:26,843 [INFO] parallelexecution      commited chunk: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    adsh     cik       name     sic countryba stprba  \\\n",
      "0   0000320193-22-000108  320193  APPLE INC  3571.0        US     CA   \n",
      "1   0000320193-21-000105  320193  APPLE INC  3571.0        US     CA   \n",
      "2   0000320193-20-000096  320193  APPLE INC  3571.0        US     CA   \n",
      "3   0000320193-19-000119  320193  APPLE INC  3571.0        US     CA   \n",
      "4   0000320193-18-000145  320193  APPLE INC  3571.0        US     CA   \n",
      "5   0000320193-17-000070  320193  APPLE INC  3571.0        US     CA   \n",
      "6   0001628280-16-020309  320193  APPLE INC  3571.0        US     CA   \n",
      "7   0001193125-15-356351  320193  APPLE INC  3571.0        US     CA   \n",
      "8   0001193125-14-383437  320193  APPLE INC  3571.0        US     CA   \n",
      "9   0001193125-13-416534  320193  APPLE INC  3571.0        US     CA   \n",
      "10  0001193125-12-444068  320193  APPLE INC  3571.0        US     CA   \n",
      "11  0001193125-11-282113  320193  APPLE INC  3571.0        US     CA   \n",
      "12  0001193125-10-238044  320193  APPLE INC  3571.0        US     CA   \n",
      "13  0001193125-09-214859  320193  APPLE INC  3571.0        US     CA   \n",
      "\n",
      "       cityba  zipba                bas1  bas2  ...    period      fy  fp  \\\n",
      "0   CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20220930  2022.0  FY   \n",
      "1   CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20210930  2021.0  FY   \n",
      "2   CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20200930  2020.0  FY   \n",
      "3   CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20190930  2019.0  FY   \n",
      "4   CUPERTINO  95014  ONE APPLE PARK WAY  None  ...  20180930  2018.0  FY   \n",
      "5   CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20170930  2017.0  FY   \n",
      "6   CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20160930  2016.0  FY   \n",
      "7   CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20150930  2015.0  FY   \n",
      "8   CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20140930  2014.0  FY   \n",
      "9   CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20130930  2013.0  FY   \n",
      "10  CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20120930  2012.0  FY   \n",
      "11  CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20110930  2011.0  FY   \n",
      "12  CUPERTINO  95014   ONE INFINITE LOOP  None  ...  20100930  2010.0  FY   \n",
      "13  CUPERTINO  95014     1 INFINITE LOOP  None  ...  20090930  2009.0  FY   \n",
      "\n",
      "       filed               accepted prevrpt detail                  instance  \\\n",
      "0   20221028  2022-10-27 18:01:00.0       0      1     aapl-20220924_htm.xml   \n",
      "1   20211029  2021-10-28 18:04:00.0       0      1     aapl-20210925_htm.xml   \n",
      "2   20201030  2020-10-29 18:06:00.0       0      1     aapl-20200926_htm.xml   \n",
      "3   20191031  2019-10-30 18:13:00.0       0      1  a10-k20199282019_htm.xml   \n",
      "4   20181105  2018-11-05 08:02:00.0       0      1         aapl-20180929.xml   \n",
      "5   20171103  2017-11-03 08:02:00.0       0      1         aapl-20170930.xml   \n",
      "6   20161026  2016-10-26 16:42:00.0       0      1         aapl-20160924.xml   \n",
      "7   20151028  2015-10-28 16:31:00.0       0      1         aapl-20150926.xml   \n",
      "8   20141027  2014-10-27 17:12:00.0       0      1         aapl-20140927.xml   \n",
      "9   20131030  2013-10-29 20:38:00.0       0      1         aapl-20130928.xml   \n",
      "10  20121031  2012-10-31 17:07:00.0       0      1         aapl-20120929.xml   \n",
      "11  20111026  2011-10-26 16:35:00.0       0      1         aapl-20110924.xml   \n",
      "12  20101027  2010-10-27 16:36:00.0       0      1         aapl-20100925.xml   \n",
      "13  20091027  2009-10-27 16:18:00.0       1      0         aapl-20090926.xml   \n",
      "\n",
      "   nciks  aciks  \n",
      "0      1   None  \n",
      "1      1   None  \n",
      "2      1   None  \n",
      "3      1   None  \n",
      "4      1   None  \n",
      "5      1   None  \n",
      "6      1   None  \n",
      "7      1   None  \n",
      "8      1   None  \n",
      "9      1   None  \n",
      "10     1   None  \n",
      "11     1   None  \n",
      "12     1   None  \n",
      "13     1   None  \n",
      "\n",
      "[14 rows x 36 columns]\n",
      "(2246, 10)\n",
      "(7925, 9)\n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.companycollecting import CompanyReportCollector\n",
    "\n",
    "apple_cik = 320193\n",
    "# load the data for all 10-K (annual) reports of apple\n",
    "collector = CompanyReportCollector.get_company_collector(ciks=[apple_cik],\n",
    "                                                         forms_filter=[\"10-K\"])\n",
    "\n",
    "rawdatabag = collector.collect()\n",
    "\n",
    "# all filed 10-K reports for apple since 2010 are in the databag\n",
    "print(rawdatabag.sub_df)\n",
    "\n",
    "print(rawdatabag.pre_df.shape)\n",
    "print(rawdatabag.num_df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8536b-c775-48a2-8c58-159d569e5acf",
   "metadata": {},
   "source": [
    "## Raw Processing: working with the raw data\n",
    "When the `collect` method of a `Collector` class is called, the data for the sub, pre, and num dataframes are loaded\n",
    "and being stored in the sub_df, pre_df, and num_df attributes inside an instance of `RawDataBag`.\n",
    "\n",
    "The `RawDataBag` provides the following methods:\n",
    "* `save`, `load`<br> The content of a `RawDataBag` can be saved into a directory. Within that directory, \n",
    "   parquet files are stored for the content of the sub_df, pre_df, and num_df. In order to load this \n",
    "   data directly, the static method `RawDataBag.load()` can be used.\n",
    "* `concat`<br> Several instances of a `RawDataBag` can be concatenated in one single instance. In order to do \n",
    "   that, the static method `RawDataBag.concat()` takes a list of RawDataBag as parameter.\n",
    "* `join` <br> This method produces a `JoinedRawDataBag` by joining the content of the pre_df and num_df\n",
    "   based on the columns adsh, tag, and version. It is an inner join. The joined dataframe appears as pre_num_df in\n",
    "   the `JoinedRawDataBag`.\n",
    "* `filter` <br> The filter method takes a parameter of the type `FilterRaw`, applies it to the data and\n",
    "   produces a new instance of `RawDataBag` with the filtered data. Therefore, filters can also be chained like\n",
    "   `a_filtered_RawDataBag = a_RawDataBag.filter(filter1).filter(filter2)`. Moreover, the `__get__item` method\n",
    "   is forwarded to the filter method, so you can also write `a_filtered_RawDataBag = a_RawDataBag[filter1][filter2]`.\n",
    "\n",
    "It is simple to write your own filters, just get some inspiration from the once that are already present in the\n",
    "Framework (module `secfsdstools.e_filter.rawfiltering`:\n",
    "\n",
    "* `AdshRawFilter` <br> Filters the `RawDataBag` instance based on the list of adshs that were provided in the constructor. <br>\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(AdshRawFilter(adshs=['0001193125-09-214859', '0001193125-10-238044']))\n",
    "   ````\n",
    "* `StmtRawFilter` <br> Filters the `RawDataBag`instance based on the list of statements ('BS', 'CF', 'IS', ...). <br>\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(StmtRawFilter(stmts=['BS', 'IS']))\n",
    "   ````\n",
    "* `TagRawFilter` <br> Filters the `RawDataBag`instance based on the list of tags that is provided. <br>\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(TagRawFilter(tags=['Assets', 'Liabilities']))\n",
    "   ````\n",
    "* `MainCoregRawFilter` <br> Filters the `RawDataBag` so that data of subsidiaries are removed.\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(MainCoregRawFilter()) \n",
    "   ````\n",
    "* `ReportPeriodAndPreviousPeriodRawFilter` <br> The data of a report usually also contains data from previous years.\n",
    "  However, often you want just to analyze the data of the current and the previous year. This filter ensures that\n",
    "  only data for the current period and the previous period are contained in the data.\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(ReportPeriodAndPreviousPeriodRawFilter()) \n",
    "   ````\n",
    "* `ReportPeriodRawFilter` <br> If you are just interested only in the data of a report that is from the current period\n",
    "  of the report then you can use this filter. For instance, if you use a `CompanyReportCollector` to collect all\n",
    "  10-K reports of this company, you want to ensure that every report only contains data for its period and not for\n",
    "  previous periods.\n",
    "   ````\n",
    "   a_filtered_RawDataBag = a_RawDataBag.filter(ReportPeriodRawFilter()) \n",
    "   ````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abdfe1-96d0-4479-9cf4-e4db6b5f16e0",
   "metadata": {},
   "source": [
    "## Joined Processing: working with joined data\n",
    "When the `join` method of a `RawDataBag` instance is called an instance of `JoinedDataBag` is returned. The returned\n",
    "instance contains an attribute sub_df, which is a reference to the same sub_df that is in the `RawDataBag`.\n",
    "In addition to that, the `JoinedDataBag` contains an attribut pre_num_df, which is an inner join of the pre_df and \n",
    "the num_df based on the columns adsh, tag, and version. Note that an entry in the pre_df can be joined with more than \n",
    "one entry in the num_df.\n",
    "\n",
    "The `JoinedDataBag` provides the following methods:\n",
    "* `save`, `load`<br> The content of a `JoinedDataBag` can be saved into a directory. Within that directory,\n",
    "  parquet files are stored for the content of the sub_df, pre_df, and num_df. In order to load this\n",
    "  data directly, the static method `JoinedDataBag.save()` can be used.\n",
    "* `concat`<br> Several instances of a `JoinedDataBag` can be concatenated in one single instance. In order to do\n",
    "  that, the static method `JoinedDataBag.concat()` takes a list of RawDataBag as parameter.\n",
    "* `filter` <br> The filter method takes a parameter of the type `FilterJoined`, applies it to the data and\n",
    "  produces a new instance of `JoinedDataBag` with the filtered data. Therefore, filters can also be chained like\n",
    "  `a_filtered_JoinedDataBag = a_JoinedDataBag.filter(filter1).filter(filter2)`. Moreover, the `__get__item` method\n",
    "  is forwarded to the filter method, so you can also write `a_filtered_JoinedDataBag = a_JoinedDataBag[filter1][filter2]`.\n",
    "  **Note**: There aren't any filters for the JoinedDataBag in the framework yet. However, you can write them in the same\n",
    "  way as a filter for a `RawDataBag` is being written.\n",
    "* `present` <br> The idea of the present method is to make a final presentation of the data as pandas dataframe. \n",
    "  The method has a parameter presenter of type Presenter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308f46f-0d34-4595-9c04-74798f3b2021",
   "metadata": {},
   "source": [
    "## Present\n",
    "It is simple to writer your own presenter classes. So far, the framework provides the following Presenter \n",
    "implementations (module `secfsdstools.e_presenter.presenting`):\n",
    "\n",
    "* `StandardStatementPresenter` <br> This presenter provides the data in the same form, as you are used to see in\n",
    "  the reports itself. For instance, the primary financial statements balance sheet, income statement, and cash flow\n",
    "  display the different positions in rows and the columns contain the different dates/periods of the data.\n",
    "  Let us say you want to recreate the BS information of the apples 10-K report of 2022, you would write:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03cc9462-4bb1-4b6b-89b6-746c7a215dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:08:36,476 [INFO] configmgt  reading configuration from /home/sebacastillo/.secfsdstools.cfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    adsh coreg  \\\n",
      "0   0000320193-22-000108         \n",
      "1   0000320193-22-000108         \n",
      "2   0000320193-22-000108         \n",
      "3   0000320193-22-000108         \n",
      "4   0000320193-22-000108         \n",
      "5   0000320193-22-000108         \n",
      "6   0000320193-22-000108         \n",
      "7   0000320193-22-000108         \n",
      "8   0000320193-22-000108         \n",
      "9   0000320193-22-000108         \n",
      "10  0000320193-22-000108         \n",
      "11  0000320193-22-000108         \n",
      "12  0000320193-22-000108         \n",
      "13  0000320193-22-000108         \n",
      "14  0000320193-22-000108         \n",
      "15  0000320193-22-000108         \n",
      "16  0000320193-22-000108         \n",
      "17  0000320193-22-000108         \n",
      "18  0000320193-22-000108         \n",
      "19  0000320193-22-000108         \n",
      "20  0000320193-22-000108         \n",
      "21  0000320193-22-000108         \n",
      "22  0000320193-22-000108         \n",
      "23  0000320193-22-000108         \n",
      "24  0000320193-22-000108         \n",
      "25  0000320193-22-000108         \n",
      "26  0000320193-22-000108         \n",
      "27  0000320193-22-000108         \n",
      "28  0000320193-22-000108         \n",
      "29  0000320193-22-000108         \n",
      "30  0000320193-22-000108         \n",
      "\n",
      "                                                tag       version stmt  \\\n",
      "0             CashAndCashEquivalentsAtCarryingValue  us-gaap/2022   BS   \n",
      "1                       MarketableSecuritiesCurrent  us-gaap/2022   BS   \n",
      "2                      AccountsReceivableNetCurrent  us-gaap/2022   BS   \n",
      "3                                      InventoryNet  us-gaap/2022   BS   \n",
      "4                        NontradeReceivablesCurrent  us-gaap/2022   BS   \n",
      "5                                OtherAssetsCurrent  us-gaap/2022   BS   \n",
      "6                                     AssetsCurrent  us-gaap/2022   BS   \n",
      "7                    MarketableSecuritiesNoncurrent  us-gaap/2022   BS   \n",
      "8                      PropertyPlantAndEquipmentNet  us-gaap/2022   BS   \n",
      "9                             OtherAssetsNoncurrent  us-gaap/2022   BS   \n",
      "10                                 AssetsNoncurrent  us-gaap/2022   BS   \n",
      "11                                           Assets  us-gaap/2022   BS   \n",
      "12                           AccountsPayableCurrent  us-gaap/2022   BS   \n",
      "13                          OtherLiabilitiesCurrent  us-gaap/2022   BS   \n",
      "14             ContractWithCustomerLiabilityCurrent  us-gaap/2022   BS   \n",
      "15                                  CommercialPaper  us-gaap/2022   BS   \n",
      "16                              LongTermDebtCurrent  us-gaap/2022   BS   \n",
      "17                               LiabilitiesCurrent  us-gaap/2022   BS   \n",
      "18                           LongTermDebtNoncurrent  us-gaap/2022   BS   \n",
      "19                       OtherLiabilitiesNoncurrent  us-gaap/2022   BS   \n",
      "20                            LiabilitiesNoncurrent  us-gaap/2022   BS   \n",
      "21                                      Liabilities  us-gaap/2022   BS   \n",
      "22     CommonStocksIncludingAdditionalPaidInCapital  us-gaap/2022   BS   \n",
      "23               RetainedEarningsAccumulatedDeficit  us-gaap/2022   BS   \n",
      "24  AccumulatedOtherComprehensiveIncomeLossNetOfTax  us-gaap/2022   BS   \n",
      "25                               StockholdersEquity  us-gaap/2022   BS   \n",
      "26                 LiabilitiesAndStockholdersEquity  us-gaap/2022   BS   \n",
      "27              CommonStockParOrStatedValuePerShare  us-gaap/2022   BS   \n",
      "28                      CommonStockSharesAuthorized  us-gaap/2022   BS   \n",
      "29                          CommonStockSharesIssued  us-gaap/2022   BS   \n",
      "30                     CommonStockSharesOutstanding  us-gaap/2022   BS   \n",
      "\n",
      "    report  line     uom  negating  inpth      20220930      20210930  \n",
      "0        5     3     USD         0      0  2.364600e+10  3.494000e+10  \n",
      "1        5     4     USD         0      0  2.465800e+10  2.769900e+10  \n",
      "2        5     5     USD         0      0  2.818400e+10  2.627800e+10  \n",
      "3        5     6     USD         0      0  4.946000e+09  6.580000e+09  \n",
      "4        5     7     USD         0      0  3.274800e+10  2.522800e+10  \n",
      "5        5     8     USD         0      0  2.122300e+10  1.411100e+10  \n",
      "6        5     9     USD         0      0  1.354050e+11  1.348360e+11  \n",
      "7        5    11     USD         0      0  1.208050e+11  1.278770e+11  \n",
      "8        5    12     USD         0      0  4.211700e+10  3.944000e+10  \n",
      "9        5    13     USD         0      0  5.442800e+10  4.884900e+10  \n",
      "10       5    14     USD         0      0  2.173500e+11  2.161660e+11  \n",
      "11       5    15     USD         0      0  3.527550e+11  3.510020e+11  \n",
      "12       5    18     USD         0      0  6.411500e+10  5.476300e+10  \n",
      "13       5    19     USD         0      0  6.084500e+10  4.749300e+10  \n",
      "14       5    20     USD         0      0  7.912000e+09  7.612000e+09  \n",
      "15       5    21     USD         0      0  9.982000e+09  6.000000e+09  \n",
      "16       5    22     USD         0      0  1.112800e+10  9.613000e+09  \n",
      "17       5    23     USD         0      0  1.539820e+11  1.254810e+11  \n",
      "18       5    25     USD         0      0  9.895900e+10  1.091060e+11  \n",
      "19       5    26     USD         0      0  4.914200e+10  5.332500e+10  \n",
      "20       5    27     USD         0      0  1.481010e+11  1.624310e+11  \n",
      "21       5    28     USD         0      0  3.020830e+11  2.879120e+11  \n",
      "22       5    31     USD         0      0  6.484900e+10  5.736500e+10  \n",
      "23       5    32     USD         0      0 -3.068000e+09  5.562000e+09  \n",
      "24       5    33     USD         0      0 -1.110900e+10  1.630000e+08  \n",
      "25       5    34     USD         0      0  5.067200e+10  6.309000e+10  \n",
      "26       5    35     USD         0      0  3.527550e+11  3.510020e+11  \n",
      "27       6     1     USD         0      1  0.000000e+00  0.000000e+00  \n",
      "28       6     2  shares         0      1  5.040000e+10  5.040000e+10  \n",
      "29       6     3  shares         0      1  1.594342e+10  1.642679e+10  \n",
      "30       6     4  shares         0      1  1.594342e+10  1.642679e+10  \n"
     ]
    }
   ],
   "source": [
    "from secfsdstools.e_collector.reportcollecting import SingleReportCollector\n",
    "from secfsdstools.e_filter.rawfiltering import ReportPeriodAndPreviousPeriodRawFilter\n",
    "from secfsdstools.e_presenter.presenting import StandardStatementPresenter\n",
    "\n",
    "apple_10k_2022_adsh = \"0000320193-22-000108\"\n",
    "\n",
    "collector: SingleReportCollector = SingleReportCollector.get_report_by_adsh(\n",
    "    adsh=apple_10k_2022_adsh,\n",
    "    stmt_filter=[\"BS\"]\n",
    ")\n",
    "rawdatabag = collector.collect()\n",
    "bs_df = (rawdatabag.filter(ReportPeriodAndPreviousPeriodRawFilter())\n",
    "                .join()\n",
    "                .present(StandardStatementPresenter()))\n",
    "print(bs_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cd5f9-ace5-4ab4-ba80-01411bfcc23f",
   "metadata": {},
   "source": [
    " If you compare this with the real report at https://www.sec.gov/ix?doc=/Archives/edgar/data/320193/000032019322000108/aapl-20220924.htm\n",
    "  you will notice, that order of the tags and the values are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bfa5f-e965-464e-9479-4017e1745b88",
   "metadata": {},
   "source": [
    "## What to do next\n",
    "Definitely checkout the notebook \"03_explore_with_interactive_notebook.ipynb\" which shows some example on how the data can be explored in an interactive way in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75badc-c80b-4dae-ac87-5de378c61fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
