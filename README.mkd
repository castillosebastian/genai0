# GenAI Project Template and Notes (periodically updated)

## Inspired by [Deeplearning.ai](https://www.deeplearning.ai/courses/generative-ai-with-llms/)

This repository maintains a limited selection of resources and articles related to the field of GenAI and its application to chatbots (with a focus on RAG-type architectures). The general purpose is to test the solutions proposed in this field using open source LLMs. Any contribution is welcome.    

In this context, we divided the content of our notes and testing following the GenAI development applications model proposed in the course dictated by Deeplearning.ai. The model or template has 6 steps: 

1. Define use case
2. Chose an existing model or pre-train your own
3. Adapt and align model
   1. prompt engineering
   2. fine tunning
   3. align with human feedback
4. Evaluate
5. Optimize
6. Deploy

This are the tools and resources: 

## Tools and resources:
  
1. Use case: **GenAI for chatbot in the Finance Sector**:
   1. Architecture definitions?
   2. Specific use cases? eg.RAG 
   3. Data characteristics and format? see: *tables-doc-problem*, 
   4. Legal compliance requirements? *High Risk AI* according to [EU_AI_Act](https://artificialintelligenceact.com/)
   
2. Existing models:
   1. [LLama2-chat](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)  
   2. [FinMA](https://huggingface.co/ChanceFocus/finma-7b-full)
   3. [FinGPT](https://huggingface.co/FinGPT)
   4. [Mistral-7b](https://huggingface.co/docs/transformers/main/model_doc/mistral)
   5. [Mistral-8x7b-SMoe](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1), [2](https://huggingface.co/blog/mixtral), [3](https://arxiv.org/abs/2101.03961), [4](https://arxiv.org/pdf/2305.14705.pdf)      
   6. ...
   7. Private Models: [BloombergGPT](https://arxiv.org/abs/2303.17564)  

3. Adapt and Align (AA):  
   1. AA:Prompt:    
      1. [MedPrompt](https://arxiv.org/abs/2311.16452)    
   2. AA:FineTune:   
      1. [AdaptLLMstoDomains](https://huggingface.co/AdaptLLM/finance-LLM)
      2. [ft_llama2_LoRA](https://arxiv.org/abs/2308.13032): summarization and NER.
   3. AA: Aling and HF    
      1. [Pearl](https://pearlagent.github.io/)

4. Evaluation
   1. [Promptbench](https://promptbench.readthedocs.io/en/latest/examples/basic.html)
   2. [TrueLens](https://www.trulens.org/), [2](https://blog.llamaindex.ai/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c)
   3. [notes1](https://www.philschmid.de/evaluate-llm)

5. Optimize
   ...

6. Deploy
   ...


## Scripts Tested

All testing is made in a VM on Google Cloud free tier: 24 vCPU, 84G RAM, 100G Disk, Ubuntu 22. I made an installation [script](https://github.com/castillosebastian/genai0/blob/main/related_works/Cloud_VM/instalar.sh) to run a non-secure IDE. When the installation is finish, to create the Python environment follow:

a. `python3 -m venv ~/.genai0`   
b. `source  ~/.genai0/bin/activate`   
c. `python3 -m pip install --upgrade pip`   
d. `pip install -r requirements.txt`    
e. Set interpreter in Project settings: Type and select "Python: Select Interpreter." Choose the interpreter from your .genai0 virtual environment. It should be something like /root/.genai0/bin/python3.     

2. Models tested
   1. [Zphyr-7b_gen_exploration](https://github.com/castillosebastian/genai0/blob/main/related_works/Cloud_VM/rag2_ok_HugFace-zepyyr.py)
   2. [llama-2-chat-13b-ggml_Q4](https://github.com/castillosebastian/genai0/blob/main/related_works/Cloud_VM/rag3_ok_LLama2-13b_Q4.py)
   3. [FinMa-7b-full_part1](https://github.com/castillosebastian/genai0/blob/main/related_works/Cloud_VM/rag4_FinMA-7bfull.py)
   4. [Mistral7b-Q4](https://github.com/castillosebastian/genai0/blob/main/related_works/Cloud_VM/rag5_Mistral7b_Q4.py)

